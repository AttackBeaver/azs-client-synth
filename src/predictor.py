import os
import json
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score


def load_json(path: str):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

# === Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ„Ğ¸Ñ‡ ===


def infer_feature_info(feature_hypotheses, feature_name):
    """
    ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·Ñ‹ Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ¸Ñ‡Ğ¸. Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒ dict Ñ ĞºĞ»ÑÑ‡Ğ°Ğ¼Ğ¸:
    'feature_name', 'description', 'target_metric', 'applicable_to', 'expected_lift_visits', 'expected_lift_spend'
    Ğ•ÑĞ»Ğ¸ expected lifts Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚, Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ»ÑÑ‡Ğ¸ â€” Ğ¸Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ compute_default_lifts().
    """
    for f in feature_hypotheses:
        if f.get("feature_name") == feature_name:
            return f
    raise KeyError(
        f"Feature '{feature_name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ² feature_hypotheses.")


def compute_default_lifts(feature_info):
    """
    Ğ•ÑĞ»Ğ¸ Ñƒ Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·Ñ‹ Ğ½ĞµÑ‚ Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ½Ñ‹Ñ… expected_lift, Ğ²Ñ‹Ğ´Ğ°Ñ‘Ğ¼ Ñ€Ğ°Ğ·ÑƒĞ¼Ğ½Ñ‹Ğµ Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚Ñ‹ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ñƒ Ñ„Ğ¸Ñ‡Ğ¸.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ dict: {'lift_visits': float, 'lift_spend': float}
    */
    """
    name = feature_info.get("feature_name", "").lower()
    # Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° â€” ÑĞ¼Ğ¿Ğ¸Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ
    if "ÑĞºĞ¸Ğ´Ğº" in name or "cashback" in name or "ĞºÑÑˆĞ±ÑĞº" in name:
        return {"lift_visits": 0.08, "lift_spend": 0.05}
    if "Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´" in name or "recommend" in name:
        return {"lift_visits": 0.02, "lift_spend": 0.12}
    if "ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»" in name or "notification" in name:
        return {"lift_visits": 0.05, "lift_spend": 0.03}
    if "Ğ¿Ğ°ĞºĞµÑ‚" in name or "ĞºĞ¾Ñ€Ğ¿Ğ¾Ñ€Ğ°Ñ‚Ğ¸Ğ²" in name:
        # Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ²Ğ¸Ğ·Ğ¸Ñ‚Ğ¾Ğ², Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¾Ğ±ÑŠÑ‘Ğ¼Ğ°
        return {"lift_visits": -0.05, "lift_spend": 0.12}
    if "Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚" in name or "ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ" in name:
        return {"lift_visits": 0.06, "lift_spend": 0.04}
    if "ÑĞºĞ¾Ğ»Ğ¾Ğ³" in name or "eco" in name:
        return {"lift_visits": 0.02, "lift_spend": 0.03}
    # Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚
    return {"lift_visits": 0.05, "lift_spend": 0.05}


def estimate_response_prob(row, portraits_rules, target_metric):
    """
    ĞÑ†ĞµĞ½ĞºĞ° Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ° ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°, ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ¾Ğ².
    Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ Ğ´Ğ»Ñ Ğ¿Ğ¾Ñ€Ñ‚Ñ€ĞµÑ‚Ğ° Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°.
    """
    portrait = row.get("portrait_name")
    rules = portraits_rules.get(portrait, {})
    base = rules.get(target_metric, None)
    if base is None:
        # Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        base = 0.03
    # ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
    visits_factor = min(row.get("visits_per_month", 0) / 12.0, 1.0)
    spend_factor = min(row.get("avg_spend_per_visit", 0) / 10000.0, 1.0)
    prob = base + 0.4 * visits_factor + 0.2 * spend_factor
    prob = min(prob, 0.99)
    return prob

# === Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ ===


def run_behavior_forecast(
    mapped_df: pd.DataFrame,
    sim_df: pd.DataFrame,
    portraits_rules: dict,
    feature_hypotheses: list,
    feature_name: str,
    train_model: bool = True,
    save_to: str = None
):
    """
    ĞŸĞ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ²Ğ¸Ğ·Ğ¸Ñ‚Ğ¾Ğ² Ğ¸ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ñ‡ĞµĞºĞ° Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ feature_name.

    Ğ’Ñ…Ğ¾Ğ´Ñ‹:
    - mapped_df: DataFrame Ñ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ°Ğ¼Ğ¸ client_id, portrait_name, visits_per_month, avg_spend_per_visit, ...
    - sim_df: DataFrame Ñ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸ÑĞ¼Ğ¸ (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ None). ĞĞ¶Ğ¸Ğ´Ğ°ĞµÑ‚ÑÑ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° f"response_to_{feature_name}" ĞµÑĞ»Ğ¸ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ¸Ğ»Ğ°ÑÑŒ.
    - portraits_rules: dict Ğ¸Ğ· behavior_rules.json
    - feature_hypotheses: ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ· (feature_hypotheses.json)
    - feature_name: Ğ¸Ğ¼Ñ Ñ„Ğ¸Ñ‡Ğ¸ Ğ´Ğ»Ñ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸
    - train_model: ĞµÑĞ»Ğ¸ True Ğ¸ Ğ² sim_df ĞµÑÑ‚ÑŒ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ñ‹Ğµ Ñ†ĞµĞ»Ğ¸ â€” Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¾Ñ€Ñ‹
    - save_to: Ğ¿ÑƒÑ‚ÑŒ (Ğ¿Ğ°Ğ¿ĞºĞ°) Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² CSV (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)

    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ tuple (client_forecast_df, portrait_agg_df)
    """
    # ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ DF
    df = mapped_df.copy().reset_index(drop=True)
    if "client_id" not in df.columns:
        df["client_id"] = df.index.astype(str)

    # Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾ Ğ¿Ğ¾ Ñ„Ğ¸Ñ‡Ğµ
    feature_info = infer_feature_info(feature_hypotheses, feature_name)
    target_metric = feature_info.get("target_metric")
    applicable = feature_info.get("applicable_to", [])

    # Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ lifts
    lifts = {}
    lifts["lift_visits"] = feature_info.get("expected_lift_visits")
    lifts["lift_spend"] = feature_info.get("expected_lift_spend")
    # ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ â€” Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚Ğ½Ñ‹Ğµ
    defaults = compute_default_lifts(feature_info)
    if lifts["lift_visits"] is None:
        lifts["lift_visits"] = defaults["lift_visits"]
    if lifts["lift_spend"] is None:
        lifts["lift_spend"] = defaults["lift_spend"]

    # Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¾Ñ‚ĞºĞ»Ğ¸Ğº Ğ¸Ğ· sim_df
    response_col = f"response_to_{feature_name}"
    has_response_column = sim_df is not None and response_col in sim_df.columns

    # ÑĞ»Ğ¸Ğ²Ğ°ĞµĞ¼ sim_df (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ) Ğ¿Ğ¾ client_id
    if sim_df is not None and "client_id" in sim_df.columns:
        df = df.merge(sim_df[["client_id", response_col]] if has_response_column else sim_df[[
                      "client_id"]], on="client_id", how="left")

    # ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ°, Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ°
    if not has_response_column:
        df[f"{response_col}_prob"] = df.apply(
            lambda r: estimate_response_prob(r, portraits_rules, target_metric), axis=1)
        # Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ) â€” Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµĞ¼ Ğ±ĞµĞ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    else:
        # ĞµÑÑ‚ÑŒ Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚ĞºĞ»Ğ¸Ğº 0/1 â€” Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ÑŒ empirical lift Ğ¿Ñ€Ğ¸ Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞµ
        df[f"{response_col}_prob"] = df[response_col]  # 0/1

    # Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ / Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ
    feat_num = ["visits_per_month",
                "avg_liters_per_visit", "avg_spend_per_visit"]
    for c in feat_num:
        if c not in df.columns:
            df[c] = 0.0

    # One-Hot ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ñ€Ñ‚Ñ€ĞµÑ‚Ğ¾Ğ² (Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸)
    ohe = OneHotEncoder(sparse_output=False, handle_unknown="ignore")
    portraits_arr = ohe.fit_transform(df[["portrait_name"]])
    portraits_cols = [f"portrait__{v}" for v in ohe.categories_[0]]
    portraits_df = pd.DataFrame(
        portraits_arr, columns=portraits_cols, index=df.index)

    # Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    X = pd.concat([df[feat_num].reset_index(drop=True),
                  portraits_df.reset_index(drop=True)], axis=1)

    # ĞµÑĞ»Ğ¸ Ğ² sim_df ĞµÑÑ‚ÑŒ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ post-Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ visits_post, spend_post), Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¸Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
    y_visits = None
    y_spend = None
    if sim_df is not None:
        # Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº â€” Ğ³Ğ¸Ğ±ĞºĞ¾ÑÑ‚ÑŒ
        possible_visits_post = [
            f"visits_after_{feature_name}", f"visits_post_{feature_name}", "visits_after", "visits_post"]
        possible_spend_post = [
            f"spend_after_{feature_name}", f"spend_post_{feature_name}", "spend_after", "spend_post", "avg_spend_post"]
        for col in possible_visits_post:
            if col in sim_df.columns:
                df = df.merge(sim_df[["client_id", col]],
                              on="client_id", how="left")
                y_visits = df[col].values
                break
        for col in possible_spend_post:
            if col in sim_df.columns:
                df = df.merge(sim_df[["client_id", col]],
                              on="client_id", how="left")
                y_spend = df[col].values
                break

    # ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ñ‹Ğµ post-Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ â€” Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµĞ¼ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¾Ñ€Ñ‹
    model_visits = None
    model_spend = None
    can_train = train_model and (y_visits is not None or y_spend is not None)

    if can_train:
        if y_visits is not None:
            # Ñ†ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ â€” Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ (post / pre)
            baseline = df["visits_per_month"].values.astype(float) + 1e-6
            y_rel_visits = y_visits / baseline
            X_train, X_val, y_train, y_val = train_test_split(
                X, y_rel_visits, test_size=0.2, random_state=42)
            model_visits = RandomForestRegressor(
                n_estimators=100, random_state=42)
            model_visits.fit(X_train, y_train)
            pred = model_visits.predict(X_val)
            print("Visits model MAE:", mean_absolute_error(
                y_val, pred), "R2:", r2_score(y_val, pred))
        if y_spend is not None:
            baseline_spend = df["avg_spend_per_visit"].values.astype(
                float) + 1e-6
            y_rel_spend = y_spend / baseline_spend
            X_train, X_val, y_train, y_val = train_test_split(
                X, y_rel_spend, test_size=0.2, random_state=42)
            model_spend = RandomForestRegressor(
                n_estimators=100, random_state=42)
            model_spend.fit(X_train, y_train)
            pred = model_spend.predict(X_val)
            print("Spend model MAE:", mean_absolute_error(
                y_val, pred), "R2:", r2_score(y_val, pred))

    # Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ°: ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ° Ğ¸ lift-Ñ‹
    # ĞµÑĞ»Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ĞµÑÑ‚ÑŒ â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¸Ñ… Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
    if model_visits is not None:
        rel_visits_pred = model_visits.predict(X)
    else:
        # baseline multiplier = 1 + prob * lift_visits
        rel_visits_pred = 1.0 + \
            df[f"{response_col}_prob"].values * lifts["lift_visits"]

    if model_spend is not None:
        rel_spend_pred = model_spend.predict(X)
    else:
        rel_spend_pred = 1.0 + \
            df[f"{response_col}_prob"].values * lifts["lift_spend"]

    # Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·ÑƒĞ¼Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¸ĞºÑ‚Ğ¾Ğ²
    rel_visits_pred = np.clip(rel_visits_pred, 0.5, 5.0)
    rel_spend_pred = np.clip(rel_spend_pred, 0.7, 5.0)

    # Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ñ‹ Ğ½Ğ° ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°
    df["baseline_visits"] = df["visits_per_month"].astype(float)
    df["baseline_spend"] = df["avg_spend_per_visit"].astype(float)
    df["pred_rel_visits"] = rel_visits_pred
    df["pred_rel_spend"] = rel_spend_pred
    df["predicted_visits"] = df["baseline_visits"] * df["pred_rel_visits"]
    df["predicted_spend"] = df["baseline_spend"] * df["pred_rel_spend"]
    df["delta_visits"] = df["predicted_visits"] - df["baseline_visits"]
    df["delta_spend"] = df["predicted_spend"] - df["baseline_spend"]
    # Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ° (Ğ² Ğ¼ĞµÑÑÑ†) Ğ´Ğ¾/Ğ¿Ğ¾ÑĞ»Ğµ
    df["baseline_revenue"] = df["baseline_visits"] * df["baseline_spend"]
    df["predicted_revenue"] = df["predicted_visits"] * df["predicted_spend"]
    df["revenue_change"] = df["predicted_revenue"] - df["baseline_revenue"]

    # Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾ Ğ¿Ğ¾Ñ€Ñ‚Ñ€ĞµÑ‚Ğ°Ğ¼
    agg = df.groupby("portrait_name").agg(
        clients_count=("client_id", "count"),
        baseline_visits=("baseline_visits", "sum"),
        predicted_visits=("predicted_visits", "sum"),
        baseline_revenue=("baseline_revenue", "sum"),
        predicted_revenue=("predicted_revenue", "sum"),
    ).reset_index()
    agg["visits_change_abs"] = agg["predicted_visits"] - agg["baseline_visits"]
    agg["revenue_change_abs"] = agg["predicted_revenue"] - agg["baseline_revenue"]
    agg["visits_change_rel"] = agg["visits_change_abs"] / \
        (agg["baseline_visits"] + 1e-9)
    agg["revenue_change_rel"] = agg["revenue_change_abs"] / \
        (agg["baseline_revenue"] + 1e-9)

    # ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
    if save_to:
        os.makedirs(save_to, exist_ok=True)
        client_path = os.path.join(
            save_to, f"forecast_clients_{feature_name}.csv")
        agg_path = os.path.join(
            save_to, f"forecast_portraits_{feature_name}.csv")
        df.to_csv(client_path, index=False)
        agg.to_csv(agg_path, index=False)

    # Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ¸ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ‚
    client_cols = [
        "client_id", "portrait_name", "baseline_visits", "predicted_visits", "delta_visits",
        "baseline_spend", "predicted_spend", "delta_spend", "baseline_revenue", "predicted_revenue", "revenue_change"
    ]
    return df[client_cols].copy(), agg.copy()


def generate_forecast_summary(clients_forecast, portraits_forecast, feature_name: str = ""):
    """
    Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾ Ğ¾Ñ„Ğ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°
    Ğ¿Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ¾Ğ².
    """

    try:
        total_visits_before = clients_forecast["baseline_visits"].sum()
        total_visits_after = clients_forecast["predicted_visits"].sum()
        total_spend_before = clients_forecast["baseline_revenue"].sum()
        total_spend_after = clients_forecast["predicted_revenue"].sum()
    except KeyError:
        raise KeyError(
            "ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° (baseline/predicted).")

    delta_visits = total_visits_after - total_visits_before
    delta_spend = total_spend_after - total_spend_before
    delta_spend_pct = (delta_spend / total_spend_before) * \
        100 if total_spend_before else 0

    # Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚
    if delta_spend > 0:
        trend = "ğŸ“ˆ Ğ Ğ¾ÑÑ‚ Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ¸"
        effect = "Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹"
        color = "ğŸŸ¢"
    elif delta_spend < 0:
        trend = "ğŸ“‰ Ğ¡Ğ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ¸"
        effect = "Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹"
        color = "ğŸ”´"
    else:
        trend = "âš–ï¸ Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚"
        effect = "Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹"
        color = "ğŸŸ¡"

    # Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾ Ğ¾Ñ„Ğ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
    summary = []
    summary.append(f"### ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ¿Ğ¾ Ñ„Ğ¸Ñ‡Ğµ: **{feature_name}**\n")
    summary.append(f"**ĞĞ±Ñ‰Ğ¸Ğ¹ Ñ‚Ñ€ĞµĞ½Ğ´:** {trend} {color}")
    summary.append("")
    summary.append("**ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸:**")
    summary.append(
        f"- Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ¸: **{delta_spend:,.0f} â‚½ ({delta_spend_pct:+.1f}%)**".replace(",", " "))
    summary.append(
        f"- Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ²Ğ¸Ğ·Ğ¸Ñ‚Ğ¾Ğ²: **{delta_visits:,.0f}**".replace(",", " "))
    summary.append("")
    summary.append(f"**ĞĞ±Ñ‰Ğ¸Ğ¹ ÑÑ„Ñ„ĞµĞºÑ‚:** {effect.capitalize()} Ğ´Ğ»Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ°.\n")

    # Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ° Ğ¿Ğ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼
    try:
        top_segments = (
            portraits_forecast.sort_values(
                "revenue_change_rel", ascending=False)
            .head(2)["portrait_name"]
            .tolist()
        )
        bottom_segments = (
            portraits_forecast.sort_values(
                "revenue_change_rel", ascending=True)
            .head(1)["portrait_name"]
            .tolist()
        )
    except KeyError:
        top_segments, bottom_segments = [], []

    if top_segments:
        summary.append("**ğŸ” ĞĞ°Ğ¸Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¹ Ñ€Ğ¾ÑÑ‚ Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµÑ‚ÑÑ Ğ² ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ…:**")
        for s in top_segments:
            summary.append(f"- {s}")
    if bottom_segments:
        summary.append("")
        summary.append("**âš ï¸ Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾Ğµ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğ² ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğµ:**")
        for s in bottom_segments:
            summary.append(f"- {s}")

    summary.append("")
    summary.append(
        "_Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ: ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ñ‚ÑĞ»ĞµĞ´Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ°ĞºÑ†Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ… Ğ¿Ğ¾ÑĞ»Ğµ Ñ€ĞµĞ»Ğ¸Ğ·Ğ°._")

    return "\n".join(summary)
